\section{Scikit-Learn}

Jupyter notebook examples can be found here: \textit{https://github.com/ageron/handson-ml2}\newline

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Introduction}

\underline{What is Machine Learning?}
\begin{itemize}
\vspace{-4.0mm}
\item
ML is about making machines get better at some task by learning from data,
instead of having to explicitly code rules.
\item
A computer program is said to learn from experience E with respect to some task T and some performance measure P,
if its performance on T, as measured by P, improves with experience E.
\end{itemize}

\vspace{-4.0mm}
\underline{Jargon:}
\begin{itemize}
\vspace{-4.0mm}
\item
\textbf{Regression:} predicting values using features/predictors.
\item
\textbf{Classification:} predicting classifications using features/predictors.
\item
\textbf{Supervised learning:}
the training data includes the desired solutions, called labels.\newline
\textit{The label is either a target value or a classification.}
\item
\textbf{Unsupervised learning:}
the training data is unlabeled.\newline
\textit{E.g. clustering, anomaly detection, visualization, and dimensionality reduction.}
\item
\textbf{Semi-supervised learning:}
the training data is partially labeled.\newline
\textit{This is normally performed by a combination of unsupervised and supervised algorithms.}
\item
\textbf{Reinforcement learning:}
the agent observes the environment, selects/performs actions, and gets rewards/penalties in return.
Over time it learns the best strategy to maximize reward.
\item
\textbf{Batch/Offline learning:}
process all the data in one go.
\item
\textbf{Online learning:}
the system is trained incrementally by feeding it data sequentially.
\item
\textbf{Data mining:}
applying ML techniques to dig into large amounts of data
to help discover patterns that were not immediately apparent.
\item
\textbf{Cost function:}
measures how bad your model is.
\item
\textbf{Hyperparameters:}
the parameters of the learning algorithm (not the resultant model).\newline
\textit{They must be set prior to training.}
\item
\textbf{Inference:}
appyling a model to make predictions on new cases.
\item
\textbf{Feature engineering:}
is the combination of...\newline
- Feature selection: selecting the most useful features among existing features.\newline
- Feature extraction: combining existing features to produce a more useful one.\newline
- Creating new features by gathering new data.
\end{itemize}

\newpage
\underline{The main challenges of ML:}
\begin{enumerate}
\vspace{-4.0mm}
\item
\textbf{Bad data:}
\begin{itemize}
\vspace{-2.0mm}
\item
Insufficient quantity of data.
\item
Non-representative training data (sampling bias and/or sampling noise).
\item
Poor quality data (errors, outliers, and noise).
\item
Irrelevant features (garbage in = garbage out).
\end{itemize}
\item
\textbf{Bad algorithm:}
\begin{itemize}
\vspace{-2.0mm}
\item
\underline{Overfitting} the training data.\newline
\textit{The model performs well on training data, but it does not generalise well.}\newline
This happens when the model is too complex relative to the amount and the noisiness of the training data.
Solutions:\newline
- Select a simpler model or constrain your current model through regularization.\newline
- Obtain more training data and/or reduce the noise in the training data.
\item
\underline{Underfitting} the training data.\newline
\textit{The model is too simple to learn the underlying structure of the data.}
Solutions:\newline
- Reduce constraints on your model or select a more powerful model.\newline
- Feed better features to the learning algorithm (feature engineering).
\end{itemize}
\end{enumerate}

\vspace{+3.0mm}
\underline{Testing and validating a ML model}
\begin{itemize}
\vspace{-3.0mm}
\item
The only way to know how well a model generalizes, is to actually try it out on new cases.
\item
Split the data into two sets: a training set and a test set (typically with a 80:20 split).\newline
\textit{The error on test set is called the generalization error.
If the training error is low, but the generalization error is high, it means you are overfitting the training data.}
\end{itemize}

\vspace{+3.0mm}
\underline{Hyperparameter tuning and model selection}
\begin{itemize}
\vspace{-3.0mm}
\item
You cannot use the test set to tune hyperparameters or select a model.\newline
\textit{In doing so, your model would just adapt to that particular set,
and your generalization error will no longer be a valid estimate.}
\item
Instead, use a validation (development) set from part of the training set.
\item
\textbf{Cross validation} uses many small validation sets.
Each model is evaluated once per validation set after it is trained on the rest of the data.
By averaging out all the evaluations of a model,
you get a much more accurate measure of its performance.
\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsection{End-to-end ML (Regression)}

To avoid a data snooping bias, immediately create a randomized test set.\newline
\texttt{from sklearn.model\char`_selection import train\char`_test\char`_split}\newline
\texttt{train, test = train\char`_test\char`_split(data, test\char`_size=0.2, random\char`_state=42)}\newline

Exploratory analysis to gain insights.
\begin{itemize}
\vspace{-3.0mm}
\item
Plot distributions:\newline
\texttt{train.hist(bins=50, figsize=(20,15))} 
\item
Plot correlations:\newline
\texttt{from pandas.plotting import scatter\char`_matrix}\newline
\texttt{scatter\char`_matrix(train, figsize=(12,8))}
\item
Study correlation coefficients:\newline
\texttt{corr\char`_matrix = train.corr()}\newline
\texttt{corr\char`_matrix[\textquotesingle median\char`_house\char`_value\textquotesingle].sort\char`_values(ascending=False)}
\item
Transform attributes and/or try out various combinations of attributes:\newline
\texttt{train[\textquotesingle rooms\char`_per\char`_house\textquotesingle] = train[\textquotesingle total\char`_rooms\textquotesingle]/train[\textquotesingle houses\textquotesingle]}\newline
\texttt{train[\textquotesingle mean\char`_salary\char`_log\textquotesingle] = np.log(train[\textquotesingle mean\char`_salary\textquotesingle]+1.0)}\newline
\end{itemize}

Prepare the data for ML algorithms (wrap up as a function you can also apply to the test set).
\vspace{-3.0mm}
\begin{itemize}
\item
Data cleaning (address any NULL values):\newline
\texttt{train.dropna(subset=[\textquotesingle total\char`_rooms\textquotesingle])}~~~~get rid of the corresponding rows.\newline
\texttt{train.drop(\textquotesingle total\char`_rooms\textquotesingle, axis=1)}~~~~~~~~~~get rid of the entire attribute.\newline
\texttt{median = train[\textquotesingle total\char`_rooms\textquotesingle].median()}~~~~~~~~set to some value.\newline
\texttt{train[\textquotesingle total\char`_rooms\textquotesingle].fillna(median, inplace=True)}
\item
Separate the features and the labels:\newline
\texttt{train\char`_X = train.drop(\textquotesingle median\char`_house\char`_value\textquotesingle, axis=1)}\newline
\texttt{train\char`_y = train[\textquotesingle median\char`_house\char`_value\textquotesingle].copy()}
\item
Handle text/categorical attributes:\newline
Sometimes you can map categories onto numbers (e.g. bad, average, good, excellent).\newline
But you might have to One Hot Encode;
where you have one binary attribute per category.\newline
\textit{Note: one-hot-encoding can result in lots of input features
which slows down the model and degrades performance.}
\item
Feature Scaling:\newline
ML algos don't perform well when the input numerical features have very different scales.
\textbf{Min-max scaling (normalization)} $\rightarrow$ rescales between 0 and 1.\newline
\textit{This can be affected by outliers (consequently, you might want to take a features log first).}\newline
\textbf{Standardization} $\rightarrow$ subtracts the mean, and divides by the standard deviation.\newline
\textit{This gives a distribution with mean=0 and unit variance.
It does not bound values to a specific range (a problem with neural networks)
but is much less affected by outliers.}\newline

\texttt{from sklearn.preprocessing import MinMaxScaler \# not used here}\newline
\texttt{from sklearn.preprocessing import StandardScaler}\newline
\texttt{from sklearn.preprocessing import OneHotEncoder}\newline
\texttt{from sklearn.compose import ColumnTransformer}\newline
\newline
\texttt{cat\char`_attribs = [\textquotesingle ocean\char`_proximity\textquotesingle]}\newline
\texttt{num\char`_attribs = list(train\char`_X.drop(cat\char`_attribs, axis=1))}\newline
\newline
\texttt{full\char`_pipeline = ColumnTransformer([}\newline
\texttt{(\textquotesingle num\textquotesingle, StandardScaler(), num\char`_attribs),}\newline
\texttt{(\textquotesingle cat\textquotesingle, OneHotEncoder(), cat\char`_attribs),}\newline
\texttt{])}\newline
\newline
\texttt{train\char`_X\char`_prepared = full\char`_pipeline.fit\char`_transform(train\char`_X)}\newline
\item
To determine the order of the one-hot-encoded attributes, do the following...\newline
\texttt{cat\char`_encoder = full\char`_pipeline.named\char`_transformers\char`_[\textquotesingle cat\textquotesingle]}\newline
\texttt{cat\char`_encoder.categories\char`_[i]}
\end{itemize}

Training a model.
\vspace{-3.0mm}
\begin{itemize}
\item
Linear regression model:\newline
\texttt{from sklearn.linear\char`_model import LinearRegression}\newline
\texttt{model = LinearRegression()}\newline
\texttt{model.fit(train\char`_X\char`_prepared, train\char`_y)}
\item
Decision tree model:\newline
\texttt{from sklearn.tree import DecisionTreeRegressor}\newline
\texttt{model = DecisionTreeRegressor()}\newline
\texttt{model.fit(train\char`_X\char`_prepared, train\char`_y)}
% \item
% Random forest model:\newline
% \texttt{from sklearn.ensemble import RandomForestRegressor}\newline
% \texttt{model = RandomForestRegressor()}\newline
% \texttt{model.fit(train\char`_X\char`_prepared, train\char`_y)}
\end{itemize}

Selecting a model.
\vspace{-3.0mm}
\begin{itemize}
\item
Evaluate a model using the Root Mean Square Error (RMSE):\newline
\texttt{from sklearn.metrics import mean\char`_squared\char`_error}\newline
\texttt{train\char`_pred\char`_y = model.predict(train\char`_X\char`_prepared)}\newline
\texttt{mse = mean\char`_square\char`_error(train\char`_y, train\char`_pred\char`_y)}\newline
\texttt{rmse = np.sqrt(mse)}
\item
K-fold cross-validation (note that this doesn't result in the model being trained):\newline
- Splits the training set into $N$ distinct subsets called folds (represented by \texttt{cv} below).\newline
- Trains and evaluates the model $N$ times, resulting in $N$ evaluation scores.\newline
- It selects a different fold for evaluation every time and trains on the other $N-1$ folds.\newline
\texttt{from sklearn.model\char`_selection import cross\char`_val\char`_score}\newline
\texttt{scores = cross\char`_val\char`_score(model, train\char`_X\char`_prepared, train\char`_y,}\newline
\texttt{.~~~~~~~~~~~~~~~~~~~~~~~~scoring=\textquotesingle neg\char`_mean\char`_squared\char`_error\textquotesingle, cv=10)}\newline
\texttt{rmse\char`_scores = np.sqrt(-scores)}
% \item
% Fine tune model hyperparameters using grid search:\newline
% \texttt{from sklearn.model\char`_selection import GridSearchCV}\newline
% \texttt{dictionary\char`_1 = \{\textquotesingle n\char`_estimators\textquotesingle:[3,10,30], \textquotesingle max\char`_features\textquotesingle:[2,4,6,8]\}}\newline
% \texttt{dictionary\char`_2 = \{\textquotesingle bootstrap\textquotesingle:[False], \textquotesingle n\char`_estimators\textquotesingle:[3,10,30]\}}\newline
% \texttt{param\char`_grid = [dictionary\char`_1, dictionary\char`_2]}\newline
% \texttt{forest\char`_reg = RandomForestRegressor()}\newline
% \texttt{grid\char`_search = GridSearchCV(forest\char`_reg, param\char`_grid, cv=5,}\newline
% \texttt{.~~~~~~~~~~~~~~~~~~~~~~~~~~scoring=\textquotesingle neg\char`_mean\char`_squared\char`_error\textquotesingle,}\newline
% \texttt{.~~~~~~~~~~~~~~~~~~~~~~~~~~return\char`_training\char`_score=True)}\newline
% \texttt{grid\char`_search.fit(train\char`_X\char`_prepared, train\char`_y)}\newline
% \newline
% \texttt{grid\char`_search.best\char`_params\char`_}\newline
% \texttt{grid\char`_search.best\char`_estimator\char`_}\newline
% \texttt{grid\char`_search.cv\char`_results\char`_[\textquotesingle mean\char`_test\char`_score\textquotesingle]}\newline
% \texttt{grid\char`_search.cv\char`_results\char`_[\textquotesingle params\textquotesingle]}
\item
Study the relative importance of each attribute:\newline
\texttt{feat\char`_importances = model.feature\char`_importances}\newline
\texttt{feats = num\char`_attributes + list(cat\char`_encoder.categories\char`_[0]) + ...}\newline
\texttt{sorted(zip(feat\char`_importances, feats), reverse=True)}
\end{itemize}

Evaluate model on the test set.\newline
\texttt{test\char`_y = test[\textquotesingle median\char`_house\char`_value\textquotesingle].copy()}\newline
\texttt{test\char`_X = test.drop(\textquotesingle median\char`_house\char`_value\textquotesingle, axis=1)}\newline
\texttt{test\char`_X\char`_prepared = full\char`_pipeline.\textbf{transform}(test\char`_X)}\newline
\texttt{test\char`_pred\char`_y = final\char`_model.predict(test\char`_X\char`_prepared)}\newline
\texttt{test\char`_mse = mean\char`_square\char`_error(test\char`_y, test\char`_pred\char`_y)}\newline
\texttt{test\char`_rmse = np.sqrt(test\char`_mse)}\newline

Saving models.\newline
\texttt{import joblib}\newline
\texttt{joblib.dump(my\char`_model, \textquotesingle my\char`_model.pkl\textquotesingle)}\newline
\texttt{my\char`_model\char`_loaded = joblib.load(\textquotesingle my\char`_model.pkl\textquotesingle)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Classification}

Training a binary classification model.
Note that \texttt{train\char`_y} should be \texttt{True} or \texttt{False}.\newline
\texttt{model.fit(train\char`_X, train\char`_y)}\newline
\texttt{train\char`_pred\char`_y = model.predict(train\char`_X)}\newline
\texttt{train\char`_prob\char`_y = model.predict\char`_proba(train\char`_X)[:,1]}\newline

Perform K-fold cross-validation:
\vspace{-3.0mm}
\begin{itemize}
\item
Ensure the K-fold cross-validation contains the same percentage of positive classes.\newline
\texttt{from sklearn.model\char`_selection import StratifiedKFold}\newline
\texttt{CV = StratifiedKFold(n\char`_splits=5)}\newline

\item
The following returns the class prediction rather than an evaluation score...\newline
\texttt{from sklearn.model\char`_selection import cross\char`_val\char`_predict}\newline
\texttt{cv\char`_pred\char`_y = cross\char`_val\char`_predict(model, train\char`_X, train\char`_y, cv=CV)}\newline

\item
Or you could get the predicted probability of a positive class...\newline
\texttt{cv\char`_prob\char`_y = cross\char`_val\char`_predict(model, train\char`_X, train\char`_y, cv=CV,\newline
.~~~~~~~~~~~~~~~~~~~~~~~~~~~~~method=\textquotesingle predict\char`_proba\textquotesingle)[:,1]}\newline
\texttt{cv\char`_pred\char`_y = (cv\char`_prob\char`_y > 0.5) \# you could alter this threshold}\newline

\item
Note that some models have a decision function score rather than a probability.\newline
\texttt{cv\char`_score\char`_y = cross\char`_val\char`_predict(model, train\char`_X, train\char`_y, cv=CV,\newline
.~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~method=\textquotesingle decision\char`_function\textquotesingle)}\newline
\texttt{cv\char`_pred\char`_y = (cv\char`_score\char`_y > 0.0) \# you could alter this threshold}

\end{itemize}

Performance Measures:
\vspace{-3.0mm}
\begin{itemize}

\item
Confusion Matrix.\newline
\texttt{from sklearn.metrics import confusion\char`_matrix}\newline
\texttt{confusion\char`_matrix(train\char`_y, cv\char`_pred\char`_y)}

\texttt{~~~~~~~~~~~~~~~~~Predicted \textbf{N}egative~~Predicted \textbf{P}ositive}\newline
\texttt{Actual Negative~|~TN~~~~~~~~~~~~~~~~~FP~~~~~~~~~~~~~~~~}\newline
\texttt{Actual Positive~|~FN~~~~~~~~~~~~~~~~~TP~~~~~~~~~~~~~~~~}\newline

\item
$\textrm{Accuracy} = (\textrm{TP}+\textrm{TN}) / (\textrm{TP}+\textrm{TN}+\textrm{FP}+\textrm{FN})$\newline
Not good for skewed datasets (when some classes are much more frequent than others).

\texttt{from sklearn.metrics import accuracy\char`_score}\newline
\texttt{accuracy\char`_score(train\char`_y, cv\char`_pred\char`_y)}\newline

\item
$\textrm{Precision} = \textrm{TP} / (\textrm{TP}+\textrm{FP})$\newline
The fraction of positive class predictions that are indeed positive in actuality.

\texttt{from sklearn.metrics import precision\char`_score}\newline
\texttt{precision\char`_score(train\char`_y, cv\char`_pred\char`_y)}\newline

\item
$\textrm{Recall} = \textrm{TP} / (\textrm{TP}+\textrm{FN})$. (Also called sensitivity)\newline
The fraction of actual positive classes that are detected.

\texttt{from sklearn.metrics import recall\char`_score}\newline
\texttt{recall\char`_score(train\char`_y, cv\char`_pred\char`_y)}\newline

\item
There is a trade off between precision and recall.
Depending on what you are doing, you might favour one over the other.
E.g. you'd prioritise a high recall when detecting cancer.\newline

\item
F1 is the harmonic mean of precision and recall.
$\textrm{F1} = \frac{2}{\frac{1}{\textrm{precision}} + \frac{1}{\textrm{recall}}}$\newline
You can only get a high F1 score if both precision and recall are high.\newline
\texttt{from sklearn.metrics import f1\char`_score}\newline
\texttt{f1\char`_score(train\char`_y, cv\char`_pred\char`_y)}\newline

\item
Plot precision against recall, or both as a function of the threshold.\newline
\texttt{from sklearn.metrics import precision\char`_recall\char`_curve}\newline
\texttt{precs, recalls, thresh = precision\char`_recall\char`_curve(train\char`_y, cv\char`_prob\char`_y)}\newline
\texttt{ax1.plot(recalls, precs)}\newline
\texttt{...}\newline
\texttt{ax2.plot(thresh, precs[:-1], \textquotesingle b--\textquotesingle, label=\textquotesingle precision\textquotesingle)}\newline
\texttt{ax2.plot(thresh, recalls[:-1], \textquotesingle g--\textquotesingle, label=\textquotesingle recall\textquotesingle)}\newline

\item
Plot a ROC (Receiver Operating Characteristics) curve.\newline
This is the true-positive-rate (recall)
vs the false-positive-rate (fall-out)
$= \textrm{FP} / (\textrm{FP}+\textrm{TN})$.\newline
Fall-out is the probability of a false alarm (not a great measure for skewed datasets).\newline
\texttt{from sklearn.metrics import roc\char`_curve}\newline
\texttt{fpr, tpr, thresh = roc\char`_curve(train\char`_y, cv\char`_prob\char`_y)}\newline
\texttt{ax.plot(fpr, tpr)}\newline
\texttt{ax.set\char`_xlabel(\textquotesingle False Positive Rate (Fall-out)\textquotesingle)}\newline
\texttt{ax.set\char`_ylabel(\textquotesingle True Positive Rate (Recall)\textquotesingle)}\newline
\texttt{...}\newline
The area under this curve can be used as a performance measure.\newline
A perfect classifier would have AUC=1 and a random classifier would have AUC=0.5.
\texttt{from sklearn.metrics import roc\char`_auc\char`_score}\newline
\texttt{roc\char`_auc\char`_score(train\char`_y, cv\char`_prob\char`_y)}

\item
It might be appropriate to consider
the actual number of positives,
the predicted number of positives,
and the predicted total probability.\newline
\texttt{train\char`_y.sum()}\newline
\texttt{cv\char`_pred\char`_y.sum()}\newline
\texttt{cv\char`_prob\char`_y.sum()}\newline

\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{SHAP Plots}

Create SHAP plots to explain the output of ML models.

\texttt{import shap}\newline
\newline
\texttt{feats = num\char`_attribs}\newline
\texttt{for i in range (0, len(cat\char`_attribs)):}\newline
\texttt{.~~~feats = feats + list(cat\char`_encoder.categories\char`_[i])}\newline
\newline
\texttt{explainer = shap.TreeExplainer(model)}\newline
\texttt{shap\char`_values = explainer.shap\char`_values(train\char`_X\char`_prepared)}\newline
\newline
\texttt{shap.summary\char`_plot(shap\char`_values,}\newline
\texttt{.~~~~~~~~~~~~~~~~~train\char`_X\char`_prepared,}\newline
\texttt{.~~~~~~~~~~~~~~~~~feature\char`_names=feats,}\newline
\texttt{.~~~~~~~~~~~~~~~~~plot\char`_type=\textquotesingle dot\textquotesingle,}\newline
\texttt{.~~~~~~~~~~~~~~~~~show=False,}\newline
\texttt{.~~~~~~~~~~~~~~~~~max\char`_display=len(feats))}\newline
\texttt{fig = plt.gcf()}\newline
\texttt{fig.tight\char`_layout()}\newline
\texttt{plt.savefig(output\char`_path)}\newline

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Repository Structure}

The following demos a typical ML repo structure
(only use notebooks for exploratory work):

\texttt{datasets/2020\char`_10\char`_14/COPY\char`_create\char`_dataset.py}\newline
\texttt{datasets/2020\char`_10\char`_14/data\char`_raw.csv}\newline
\texttt{datasets/2020\char`_10\char`_14/data\char`_clean.csv}\newline
\texttt{datasets/2020\char`_10\char`_14/models/}\newline
\texttt{datasets/2020\char`_10\char`_14/models/XGBoost\char`_nEst100/COPY\char`_model\char`_training\char`_and\char`_evaluation.py}\newline
\texttt{datasets/2020\char`_10\char`_14/models/XGBoost\char`_nEst100/model.pkl}\newline
\texttt{datasets/2020\char`_10\char`_14/models/XGBoost\char`_nEst100/model\char`_evalulation.pdf}\newline
\texttt{datasets/2020\char`_10\char`_14/models/XGBoost\char`_nEst100/model\char`_evalulation.txt}\newline
\texttt{sql/redshift\char`_query.sql}\newline
\texttt{create\char`_dataset.py}\newline
\texttt{model\char`_training\char`_and\char`_evaluation.py}\newline

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Decision Trees}

Decision trees are versatile ML algos that can perform both classification and regression tasks.
They are capable of fitting complex datasets,
but they're also intuitive, with decisions that are easy to interpret
(due to this, they are often called \textit{white box models}).

You can picture a decision tree as a set of nodes
that branch off due to conditions on the feature space.
Root node = depth 0.
Leaf node = does not have any child nodes.\newline

\underline{The Classification And Regression Tree (CART) algorithm:}
\vspace{-3.0mm}
\begin{enumerate}
\item
Split the training set into two subsets using a single feature $k$ and a threshold $t_k$.\newline
Note that this produces binary trees (all nodes can only have two children).
\item
Search for the pair $(k, t_k)$ that produces the purest subsets (weighted by size)\newline
by minimizing:
\begin{equation}
J(k, t_k) = \frac{m_{\textrm{left}}}{m}G_{\textrm{left}} + \frac{m_{\textrm{right}}}{m}G_{\textrm{right}}
\end{equation}
where $m$ is the number of instances
and $G = 1 - \sum p_j^2$ (the Gini impurity)\newline
where $p_j$ is the ratio of class $j$ instances.
NB: a node is pure if $G=0$.
\item
Recursively apply the same logic.
\item
Stop if there isn't a split that reduces impurity
or when hyperparameter contraints are met.
E.g. \texttt{max\char`_depth}, \texttt{max\char`_leaf\char`_nodes}, \texttt{min\char`_samples\char`_leaf}.
\end{enumerate}

The CART algorithm is a greedy algorithm;
it searches for an optimum split at the top level, then repeats.
This is necessary, however, due to the exponential increase in nodes.

Note 1: you can also use entropy to measure the impurity of a node:
$H = - \sum p_j \, \textrm{log}_2 \, p_j$

Note 2: for regression tasks, the CART algorithm tries to minimize MSE rather than impurity.

\newpage
\underline{Classification:}\newline
\texttt{from sklearn.tree import DecisionTreeClassifier}\newline
\texttt{tree\char`_clf = DecisionTreeClassifier(max\char`_depth=2)}\newline
\texttt{tree\char`_clf.fit(X, y)}

The predicted class is that which is most common
in the training instances associated with the corresponding leaf node.\newline
\texttt{tree\char`_clf.predict(X)}

A decision tree can also estimate the probability
that an instance belongs to a particular class $k$.\newline
% 
It finds the leaf node for the instance,
and returns the ratio of class $k$ (training set) instances.\newline
\texttt{tree\char`_clf.predict\char`_proba(X)}\newline

\underline{Regression:}\newline
\texttt{from sklearn.tree import DecisionTreeRegressor}\newline
\texttt{tree\char`_reg = DecisionTreeRegressor(max\char`_depth=2)}\newline
\texttt{tree\char`_reg.fit(X, y)}

The prediction is the average target value of the
training instances associated with the corresponding leaf node.\newline
\texttt{tree\char`_reg.predict(X)}\newline

\underline{Limitations:}
\vspace{-3.0mm}
\begin{itemize}
\item
Decision trees love orthogonal decision boundaries.
Consequently, they are sensitive to training set rotation.
\textit{NB: PCA often results in a better orientation of the training data.}
\item
Decision trees are very sensitive to small variations in the training data.\newline
\textit{NB: Random Forests can limit this instability by averaging predictions over many trees.}
\item
Decision trees make very few assumptions about the training data.
If left unconstrained, the tree structure will adapt itself to the training data,
fitting it very closely - most likely overfitting it.
\textit{Regularization techniques will restrict the algos freedom during training.}
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{The Bias/Variance Trade-off}

A model's generalization error can be expressed as the sum of three very different errors:
\vspace{-3.0mm}
\begin{itemize}
\item
\textbf{Bias:}
this is due to wrong modeling assumptions, such as assuming that the data is linear when it is actually quadratic.
A high-bias model is likely to underfit the training data.
\item
\textbf{Variance:}
this is due to the model's excessive sensitivity to small variations in the training data.
A model with many degrees of freedom is likely to have a high-variance and thus overfit the training data.
\item
\textbf{Irreducible error:}
this is due to the noisiness of the data itself.
\end{itemize}

Increasing a model's complexity will typically increase its variance and reduce its bias.\newline
Conversely, reducing a model's complexity will increase its bias and reduces its variance.\newline
It's a trade-off.

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Ensemble Learning}

If you aggregate the predictions of a group of predictors (such as classifiers or regressors),
you will often get better predictions than with the best individual predictor.
% 
A group of predictors is called an ensemble.
Common ensemble methods are bagging and boosting.\newline

\underline{Bagging/Pasting}\newline
Use the same training algorithm for every predictor,
and train them on different random subsets of the training set.
For classification, use the statistical mode.
For regression, take the average.
\vspace{-3.0mm}
\begin{itemize}
\item
\textbf{Bagging:} when the sampling is performed with replacement (generally preferred).
% The name is short for bootstrap aggregating.
\item
\textbf{Pasting:} when the sampling is performed without replacement.
\end{itemize}
%
\vspace{-3.0mm}
Generally, the net result is that the ensemble has a similar bias but a lower variance
than a single predictor trained on the original training set.

A \textbf{Random Forest} is an ensemble of decision trees,
generally trained via the bagging method.
For greater tree diversity,
extra randomness is introduced when growing the trees
(this increases the bias, but reduces the variance).
\textit{Extremely Randomized Trees} have an even lower variance.

\texttt{from sklearn.ensemble import RandomForestClassifier}\newline
\texttt{model = RandomForestClassifier(n\char`_estimators=500)}

\texttt{from sklearn.ensemble import RandomForestRegressor}\newline
\texttt{model = RandomForestRegressor(n\char`_estimators=500)}\newline

\underline{Boosting}\newline
The general idea of boosting methods is to train predictors sequentially,
each trying to correct its predecessor.
Popular methods include \textit{AdaBoost} and \textit{Gradient Boosting}.

Gradient Boosting works by fitting a new predictor
to the residual errors made by the previous predictor.
% 
It has a regularization technique called \textit{shrinkage},
where a \texttt{learning\char`_rate} hyperparameter scales the contribution of each predictor.
When set to a low value,
more predictors are required in the ensemble to fit the training set,
but the predictions will usually generalize better.
% 
Note that to trade a higher bias for a lower variance,
one can train each predictor on a random subset of the training instances.

\textbf{XGBoost} (which stands for extreme gradient boosting)
is a python library which has an optimized implementation of Gradient Boosting.
Its default is to use tree based models.
Check it out, it has a very similar API to Scikit-Learn.

\texttt{import xgboost}\newline
\newline
\texttt{model = xgboost.XGBRegressor(n\char`_estimators=500)}\newline
\texttt{\# model = xgboost.XGBClassifier(n\char`_estimators=500)}\newline
\newline
\texttt{model.fit(X, y)}\newline
\texttt{y\char`_pred = model.predict(X)}

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsection{Dimensionality Reduction}

\underline{The curse of dimensionality}\newline
Many ML problems involve thousands or even millions of features for each training instance.
All these features make both training extremely slow
and it much harder to find a good solution:

\vspace{-3.0mm}
\begin{itemize}
\item
High-dimensional datasets are at risk of being very sparse,
with most training instances far away from each other.
New instances will likely be far away from a training instance,
thus making predictions unreliable as they will be based on large extrapolations.
\item
In short, the more dimensions a training set has,
the greater the risk of overfitting it.
\end{itemize}

\vspace{-3.0mm}
One solution, in theory,
would be to increase the size of the training set to reach a sufficient density of training instances.
This is unfeasible, however,
as the number of training instances required to reach a given density grows exponentially with the number of dimensions.

Fortunately,
it is often possible to considerably reduce the number of features,
turning an intractable problem into a tractable one.
This technique is called \textit{Dimensionality Reduction}.\newline
These techniques are also extremely useful for data visualization (can plot N-d in 2-d).

In most real-world problems,
training instances are not spread out uniformly across all dimensions.
Many features are almost constant, while others are highly correlated.
As a result,
all training instances lie within, or close to,
a much lower-dimension subspace (a manifold).

\underline{Principal Component Analysis}\newline
PCA identifies the hyperplane that lies closest to the data,
and then projects the data onto it.

Principal Components:
\vspace{-3.0mm}
\begin{itemize}
\item
Identify the axis that accounts for the largest amount of variance in the training set.
This is the first principal component.
\item
Find a second axis, orthogonal to the first one,
that accounts for the largest amount of remaining variance.
This is the second principal component.
\item
Continue until there are as many axes as the number of dimensions of the dataset.
\item
NB: PCA assumes the data is centered around the origin (Scikit-Learn does this for you).
\end{itemize}

\vspace{-3.0mm}
Once all $n$ principal components have been identified,
reduce the dataset down to $d$ dimensions
by projecting it onto the hyperplane defined by the first $d$ principal components $(d < n)$.

\texttt{from sklearn.decomposition import PCA}\newline
\texttt{pca = PCA(n\char`_components = 2)}\newline
\texttt{X\char`_2d = pca.fit\char`_transform(X)}\newline
The proportion of the dataset's variance that lies along each principle component is given by:\newline
\texttt{pca.explained\char`_variance\char`_ratio\char`_}

The greater the total explained variance,
the smaller the information loss.
Instead of arbitrarily deciding $d$,
you can choose a value that contains a sufficiently large proportion of the variance:\newline
\texttt{pca = PCA(n\char`_components = 0.95)}

Compression: \texttt{X\char`_reduced = pca.fit\char`_transform(X)}\newline
Decompression: \texttt{X\char`_recovered = pca.inverse\char`_transform(X\char`_reduced)}


%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\newpage
\subsection{Clustering}
The goal is to identify similar instances and group them into clusters.\newline
Note, however, that there is no universal definition of what a cluster is.\newline
This is an unsupervised learning task, as the data is not labeled.\newline

\underline{\textbf{KMeans}}\newline
\texttt{from sklearn.cluster import KMeans}\newline
\texttt{kmeans = KMeans(n\char`_clusters=5, n\char`_init=300)}\newline
\texttt{y\char`_category  = kmeans.fit\char`_predict(X) \# hard clustering}\newline
\texttt{y\char`_distances = kmeans.transform(X) ~\# soft clustering}\newline
\texttt{kmeans.cluster\char`_centres\char`_ ~~~~~~~~~~~~\# centroid coordinates}

\vspace{-3.0mm}
\begin{itemize}
\item
You must specify the number of clusters that the algorithm will find.
\item
KMeans does not behave very well when the groups have very different diameters because all it cares about
when assigning an instance to a cluster is the distance to the centroid.
\item
It is important to scale features before running the algorithm.
\item
The algorithm is guaranteed to converge, but it might find a local optimum\newline
(hence \texttt{n\char`_init} which runs the algo multiple times with different random initializations).
\end{itemize}

\vspace{-3.0mm}
Performance measure = Inertia (mean distance$^2$ between each instance and its closest centroid).\newline
\texttt{kmeans.inertia\char`_}\newline

\underline{Finding the optimal number of clusters:}

\vspace{-3.0mm}
\begin{itemize}
\item
Cannot just pick $k$ which gives the lowest inertia (it always gets lower as you increase $k$).
You could look for the `elbow' in inertia vs $k$, but this is coarse.
\item
A more precise approach is to use silhouette coefficients and the silhouette score (mean silhouette coefficient over all instances).
Silhouette coefficients vary between -1 and +1.\newline
- Coefficient of $+1$: the instance is well inside its own cluster, and far from others.\newline
- Coefficient of $\,\,\,\,0$: the instance is close to a cluster boundary.\newline
- Coefficient of $-1$: the instance may have been assigned to the wrong cluster!\newline
\texttt{from sklearn.metrics import silhouette\char`_score}\newline
\texttt{silhouette\char`_score = silhouette\char`_score(X, y\char`_category)}
\item
You want to maximize silhouette score as a function of $k$.
\item
You should also check the corresponding silhouette diagram.\newline
The shape's height indicates the number of instances the cluster contains,
and its width represents the sorted silhouette coefficients of the instances in the cluster.
The vertical dashed line indicates the silhouette score.
When most of the instances in a cluster have a lower coefficient than this score,
then the cluster is rather bad since this means its instances are much too close to other clusters.
\end{itemize}

\newpage
Silhouette diagram example:\newline
\texttt{from sklearn.metrics import silhouette\char`_samples}

\texttt{fig = plt.figure(figsize=(11, 9))}\newline
\texttt{silhouette\char`_coefficients = silhouette\char`_samples(X, y\char`_category)}\newline
\texttt{padding = len(X) // 30}\newline
\texttt{pos = padding}\newline
\texttt{ticks = []}\newline
\texttt{for i in range(k):}\newline
\texttt{.~~~coeffs = silhouette\char`_coefficients[y\char`_category == i]}\newline
\texttt{.~~~coeffs.sort()}\newline
\texttt{.~~~color = mpl.cm.Spectral(i / k)}\newline
\texttt{.~~~plt.fill\char`_betweenx(np.arange(pos, pos + len(coeffs)), 0, coeffs,}\newline
\texttt{.~~~~~~~~~~~~~~~~~~~~~facecolor=color, edgecolor=color, alpha=0.7)}\newline
\texttt{.~~~ticks.append(pos + len(coeffs) // 2)}\newline
\texttt{.~~~pos += len(coeffs) + padding}\newline
\texttt{plt.gca().yaxis.set\char`_major\char`_locator(FixedLocator(ticks))}\newline
\texttt{plt.gca().yaxis.set\char`_major\char`_formatter(FixedFormatter(range(k)))}\newline
\texttt{plt.ylabel(\textquotesingle Cluster\textquotesingle , fontsize=14)}\newline
\texttt{plt.gca().set\char`_xticks([-0.4, -0.2, 0, 0.2, 0.4, 0.6, 0.8, 1])}\newline
\texttt{plt.xlabel(\textquotesingle Silhouette Coefficient\textquotesingle , fontsize=14)}\newline
\texttt{plt.axvline(x=silhouette\char`_score, color=\textquotesingle red\textquotesingle , linestyle=\textquotesingle --\textquotesingle )}\newline

%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Gradient Descent}

\underline{Introduction:}\newline
Gradient Descent is a generic optimization algorithm capable of finding optimal solutions to a wide range of problems. 
The general idea of Gradient Descent is to tweak model parameters iteratively in order to minimize a cost function.

\underline{Method:}
\vspace{-3.0mm}
\begin{itemize}
\item
Gradient Descent starts by filling the model parameter vector, $\boldsymbol{\theta}$, with random values.
\item
It then measures the local gradient of the cost function with regard to $\boldsymbol{\theta}$.
\item
It then updates $\boldsymbol{\theta}$ in the direction of descending gradient:
$\boldsymbol{\theta}^{\textrm{next step}} = \boldsymbol{\theta} - \eta \nabla_{\boldsymbol{\theta}} \textrm{MSE} (\boldsymbol{\theta})$
\newline
where $\eta$ is the learning rate hyperparameter.
\item
This continues until the cost function converges to a minimum.
\end{itemize}

\underline{Notes:}
\vspace{-3.0mm}
\begin{itemize}
\item
Gradient Descent works best when all features have a similar scale.
\item
You want to find the global minimum, rather than a local minimum, of the cost function
\item
If $\eta$ is too small, then the algorithm will have to go through many iterations to converge.\newline
On the other hand, if $\eta$ is too high, the algorithm might diverge.
\item
\textbf{Batch Gradient Descent:}\newline
Uses all the training data (for the gradient calculation) at every step.
\item
\textbf{Stochastic Gradient Descent:}\newline
Picks a random instance in the training set (for the gradient calculation) at every step.

\textit{Pros:} the algorithm is quicker, can be used on huge training sets (only one instance needs to be in memory at each iteration),
and can escape local minima.

\textit{Cons:} the algorithm is less regular and can never perfectly converge.
A learning schedule,
which reduces $\eta$ every iteration,
can allow the algo to settle at the global minimum.

\item
\textbf{Mini-batch Gradient Descent:}\newline
Selects a small random set of instances (for the gradient calculation) at every step.

\textit{Pros:} the algorithm has a similar speed to stochastic gradient descent, but is less erratic.
\end{itemize}

\underline{Regularization:}
\vspace{-3.0mm}
\begin{itemize}
\item
You can add a regularization term to the cost function (during training only)
which forces the algorithm to fit the data whilst keeping the model parameters as small as possible.\newline
For example, Ridge Regression:
$J(\boldsymbol{\theta}) = \textrm{MSE}(\boldsymbol{\theta}) + \frac{\alpha}{2}\sum \theta_i^2$
\item
Perform early stopping: stop training as soon as the validation error reaches a minimum.
\end{itemize}

\underline{Classification:}

Linear regression:
$\hat{y} = h_{\boldsymbol{\theta}}(\boldsymbol{x}) = \boldsymbol{x}^{T} \boldsymbol{\theta}$
~~~where $x_0$ equals unity.

Logistic regression:
$\hat{p} = h_{\boldsymbol{\theta}}(\boldsymbol{x}) = \sigma({\boldsymbol{x}^{T} \boldsymbol{\theta}})$
~~~where $\sigma(t) = \frac{1}{1+\textrm{exp}(-t)}$~is the logistic function.

Log loss cost function:
$J(\boldsymbol{\theta}) = - \frac{1}{m} \sum_{i=1}^{m} \big[ y^{(i)} \, \textrm{log}(\hat{p}^{(i)}) + (1 - y^{(i)}) \, \textrm{log}(1 - \hat{p}^{(i)}) \big]$\newline
- $m$ is the number of instances being evaluated.\newline
- $y^{(i)}$ is the class (0 or 1) of the $i^{\textrm{th}}$ instance.\newline
- $\hat{p}^{(i)}$ is the modeled probability (of having class=1) for the $i^{\textrm{th}}$ instance.\newline

\underline{Softmax Regression (Multiclass Classification)}

For a given instance, $\boldsymbol{x}$, compute the \textit{softmax score} for each class:
$s_k(\boldsymbol{x}) = \boldsymbol{x}^T \boldsymbol{\theta}^{(k)}$\newline
Each class has its own parameter vector $\boldsymbol{\theta}^{(k)}$.
These are combined to create a param matrix $\boldsymbol{\Theta}$.

Softmax function:
$\hat{p}_k = \frac{\textrm{exp}(s_k(\boldsymbol{x}))}{\sum_{j=1}^{K} \textrm{exp}(s_j(\boldsymbol{x}))}$

Cross entropy cost function:
$J(\boldsymbol{\Theta}) = - \frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{K} y_k^{(i)}\, \textrm{log}(\hat{p}_k^{(i)})$\newline
- Note that when there are just two classes $(K=2)$, the log loss cost function is recovered.

\newpage